# Is it possible to have hierarchical config files? XML? Hydra?
#################### DATA LOCATION ####################
'data_file': [{"train_file": 'data/site_464_201710_30_train_0.csv', "test_file": 'data/site_464_201710_30_test_0.csv'},
              {"train_file": 'data/site_464_201710_30_train_1.csv', "test_file": 'data/site_464_201710_30_test_1.csv'},
              {"train_file": 'data/site_464_201710_30_train_2.csv', "test_file": 'data/site_464_201710_30_test_2.csv'},
              {"train_file": 'data/site_464_201710_30_train_3.csv', "test_file": 'data/site_464_201710_30_test_3.csv'},
              {"train_file": 'data/site_464_201710_30_train_4.csv', "test_file": 'data/site_464_201710_30_test_4.csv'}]
#################### MODEL LOCATION ####################
'model_type': ["RCNN"]
'model_name': ["RCNN-resnet-50"]
'base_model_path': ["models/templates/RCNN-resnet-50_5_layer_pretrained.pt",]
'output_dir': ["models/trained"]
#################### TASK ####################
'task_name': ["seedlings_temp"]
'task_description': ["We need to find hyperparameter configurations that give a consistent test MAP score on the basic model. This time with SGD and "]
# Could include optimizer hyperparams by making this nested. Maybe different config files for optimiser here?
#################### TRAINING ####################
'optimiser': ['SGD']
'learning_rate': [2.0e-2, 2.0e-1, 2.0e-3]
'momentum': [0.9]
'weight_decay': [1.0e-4]
'epochs': [2]
'patience': [50]
'valid_ratio': [0.1]
'dataloader_num_workers': [5]
'train_batch_size': [5]
'eval_batch_size': [5]
'max_seq_length': [512]
'logging_steps': [2]
'seed': [1337, 42, 666, 43110, 1234]
'device': ["cuda:0"]
'develop': [True]
